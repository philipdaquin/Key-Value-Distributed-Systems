package mr

import (
	"encoding/json"
	"fmt"
	"hash/fnv"
	"io/ioutil"
	"log"
	"net/rpc"
	"os"
	"sort"
	"time"
)

//
// Map functions return a slice of KeyValue.
//
type KeyValue struct {
	Key   string
	Value string
}

type KVstore []KeyValue

func (self KVstore) Len() int {  return len(self) }

func (self KVstore) Less(x, y int) bool { 
	if x < y { return true }
	return false 
} 

func (self KVstore) Swap(a, b int) { 
	self[a], self[b] = self[b], self[a]
}

//
// use ihash(key) % NReduce to choose the reduce
// task number for each KeyValue emitted by Map.
//
func ihash(key string) int {
	h := fnv.New32a()
	h.Write([]byte(key))
	return int(h.Sum32() & 0x7fffffff)
}

//
// main/mrworker.go calls this function.
//
// 
func Worker(mapf func(string, string) []KeyValue,
	reducef func(string, []string) string) {
	fmt.Println("ðŸ§¢ Worker ")

	// Your worker implementation here.
	var args TaskArgs = TaskArgs{WorkerStatus: None}
	
	for {
			newTask := GetNextTask(&args)
		
			switch newTask.WorkerStatus {
				case Map:
					args = MapTask(newTask, mapf)
				case Reduce:
					args = ReduceTask(newTask.ImpendingTasks, reducef, newTask.WorkerId )
				case Sleep:
					time.Sleep(500 * time.Millisecond)
					args = TaskArgs{WorkerStatus: Done}
				case Exit:	
					return 
				default:
					fmt.Println("sdasdasdasd")
		
			}
	}

	// if ok := call(coordinator, &args, &reply); ok {
	// 	fmt.Println("message went through")
	// } else { 
	// 	fmt.Println("Something went wrong")
	// }
	// uncomment to send the Example RPC to the coordinator.
	// CallExample()
}

func GetNextTask(completed *TaskArgs) TaskReply {
	fmt.Println("ðŸ§¢ Getting the next task ")

	nextTask := TaskReply{}

	ok := call("Coordinator.GetTask", completed, &nextTask) 
	
	if !ok {
		fmt.Println("Failed to get response")
		os.Exit(0)
	}
	return nextTask
}

/*
	The input data is divided into smaller chunks and processed in parallel
	by multiple worker nodes 

	- 	Each worker node applies  map function to each data chunk and generates 
		a set of intermediate key pairs

	- 	The intermediate key value pairs represent intermediate results that will be used in the next 
		state of the process 

*/
func MapTask(nextTask TaskReply, mapf func(string, string) []KeyValue) TaskArgs {
	fmt.Println("ðŸ‘· Map Worker ")
	// Retrieve the first task from the `impending`
	task := nextTask.ImpendingTasks[0]

	// Open the file associated with the retrieved trask
	// defer close 
	// check for failures
	file, err := os.Open(task)
	defer file.Close()
	if err != nil { panic(err) }

	// Read the contents of the file into a string 
	// Check for readErr
	content, readErr := ioutil.ReadAll(file)
	if readErr != nil { panic(readErr) }

	// Get the []KeyValue assocociated 
	kvs := mapf(task, string(content))

	// Insert into hashmap 
	reducedFiles := make(map[int][]KeyValue)
	for _, kv := range kvs { 
		index := ihash(kv.Key) % nextTask.NReduce
		reducedFiles[index] = append(reducedFiles[index], kv)
	}

	files := make([]string, nextTask.NReduce)

	// Create a new file , serialise the keyvalue pair 
	for idx, kvFiles := range reducedFiles { 
		fileName := fmt.Sprintf("mr-%d-%d", nextTask.WorkerId, idx)
		newFile, _ := os.Create(fileName)
		defer newFile.Close()
		encoded := json.NewEncoder(newFile)
		for _, kv := range kvFiles { 
			if err := encoded.Encode(&kv); err != nil { 
				panic(err)
			}
		}
		files[idx] = fileName
	}


	return TaskArgs{WorkerId: nextTask.WorkerId, CompletedTasks: files, WorkerStatus: Done}

}

/*
	Reduce
	The intermediate results generated by the Map operation are grouped 
	and processed by a reduce function 
	- Aggregate the values associated with each unique key adn generate the final utput 

*/
func ReduceTask(
	file []string, 
	reducef func(string, []string) string, 
	nextTaskId int,
	) TaskArgs {

	fmt.Println("ðŸš€ Reduce Worker ")

	kv := []KeyValue{}

	for _, fileName := range file {
		files, err := os.Create(fileName)

		if err != nil {  panic(err) }

		defer files.Close()

		encode := json.NewDecoder(files)

		var kvs KeyValue

		for encode.Decode(&kv) == nil {
			if encode.Decode(&kv) != nil { break }
			kv = append(kv, kvs)
		}  
		sort.Sort(KVstore(kv))
	}
	name := fmt.Sprintf("mr-out-%d", nextTaskId)
	newFile, err := os.Create(name)
	if err != nil { panic(err) }

	defer newFile.Close()

	for i := 0; i < len(kv); i++ {
		j := i
		for j < len(kv) && kv[j].Key == kv[i].Key {
			j++
		}
		values := []string{}
		for k := i; k < j; k++ {
			values = append(values, kv[k].Value)
		}
		output := reducef(kv[i].Key, values)
		fmt.Fprintf(newFile, "%v %v\n", kv[i].Key, output)
		i = j - 1
	}

	var finishedTask TaskArgs  = TaskArgs{WorkerId: nextTaskId, CompletedTasks: []string{name}, WorkerStatus:  Reduce }

	return finishedTask
}


//
// example function to show how to make an RPC call to the coordinator.
//
// the RPC argument and reply types are defined in rpc.go.
//
func CallExample() {

	// declare an argument structure.
	args := ExampleArgs{}

	// fill in the argument(s).
	args.X = 99

	// declare a reply structure.
	reply := ExampleReply{}

	// send the RPC request, wait for the reply.
	// the "Coordinator.Example" tells the
	// receiving server that we'd like to call
	// the Example() method of struct Coordinator.
	ok := call("Coordinator.Example", &args, &reply)
	if ok {
		// reply.Y should be 100.
		fmt.Printf("reply.Y %v\n", reply.Y)
	} else {
		fmt.Printf("call failed!\n")
	}
}

//
// send an RPC request to the coordinator, wait for the response.
// usually returns true.
// returns false if something goes wrong.
//
func call(rpcname string, args interface{}, reply interface{}) bool {
	// c, err := rpc.DialHTTP("tcp", "127.0.0.1"+":1234")
	sockname := coordinatorSock()
	c, err := rpc.DialHTTP("unix", sockname)
	if err != nil {
		log.Fatal("dialing:", err)
	}
	defer c.Close()

	err = c.Call(rpcname, args, reply)
	if err == nil {
		return true
	}

	fmt.Println(err)
	return false
}
